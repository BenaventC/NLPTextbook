# Classification with embeddings

```{r 600}
#les librairies du chapître
library(tidyverse)
library(tokenizers)
library(quanteda)
library(quanteda.textplots)
library(flextable)

theme_set(theme_minimal()) 

set_flextable_defaults(
  font.size = 10, theme_fun = theme_vanilla,
  padding = 6,
  background.color = "#EFEFEF")
```

**Objectifs du chapitre :**

<div>

*Jusqu'à présent, nous nous sommes consacrés au traitement des chaines de caractères, généralement dans un but univarié, examinant la distribution des termes.*

*Ce chapitre est celui d'un virage multivarié : ce qu'on va étudier ce sont les distributions conjointes des termes, au travers principalement de l'analyse de leur co-occurrences. On découvrira une large palette de techniques qui permettent de les représenter et d'identifier des thématique et la manières dont elles s'articulent. Elles sont principalement descriptive.*

</div>

L'idée d'identifier des thématiques sémantique dans un corpus de texte est ancienne. AFC, clustering et Analyses de réseaux en sont les premières tentatives qui se poursuit avec la généralisation de techniques factorielle fondée sur la décomposition SVD.

Mais l'innovation majeure est celle de la méthode LDA, dont l'apport essentiel est d'identifier les thématique au niveau des documents plutôt qu'à celui du corpus. Si dans les approches précédentes un texte sera classifié parmi l'un des k sujets que l'on cherche à identifier, désormais il se traduit par une distribution de probabilité d'appartenir à chacun des k topics.

## LSA et les autres

L'analyse des classes latentes

## Le modèle fondateur : LDA

sur ce plan On doit beaucoup à sokal et sneath

## Les variations

## Conclusion
