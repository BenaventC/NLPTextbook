{
  "hash": "547c0e899d56481209110583be761c1d",
  "result": {
    "engine": "knitr",
    "markdown": "# Jouer avec les jetons\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#les librairies du chapître\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(tokenizers)\nlibrary(quanteda)\nlibrary(quanteda.textplots)\nlibrary(flextable)\n\ntheme_set(theme_minimal()) \n\nset_flextable_defaults(\n  font.size = 10, theme_fun = theme_vanilla,\n  padding = 6,\n  background.color = \"#EFEFEF\")\n```\n:::\n\n\n**Objectifs du chapitre :**\n\n<div>\n\n*L'analyse du texte commence par découper les chaines de caractères en unités pertinentes, c'est souvent le mot, ce peut être la syllabe, la phrase, ou la lettre. Ces unités sont des jetons, les pièces élémentaire d'un traitement plus sophistiqué. cette opération permet de quantifier le texte et de le représenter sous la forme de dfm.*\n\n</div>\n\nL'étape initiale de toute analyse textuelle est de découper le texte en unités d'analyse, les *tokens*, ou jetons en français, ce qui transforme le texte écrit pour la compréhension humaine en données interprétables par l'ordinateur. Les *tokens* utilisés peuvent varier selon les objectifs de l'analyse et la nature du corpus, la granularité peut être plus ou moins fine. Les *tokens* peuvent ainsi être :\n\n-   des lettres : c'est l'unité insécable.\n-   des syllabes : ça permet de s'intéresser aux phonèmes.mais aussi d'extraire d'un mot les suffixes et préfixes, ainsi que les radicaux ( la racine du mot, ex : dés-espéré-ment).\n-   des mots : il s'agit du niveau le plus évident et le plus courant, que l'on privilégiera tout au long de ce livre, il présente aussi des difficultés car il ne coincide par avec l'unité de sens, par exemple avec les locutions: \" Président de la République\", ni avec les lexiques établis, ils peuvent prendre souvent la caractéristiques de [mots fantômes](http://stella.atilf.fr/MotsFantomes/)\n-   des phrases : c'est l'unité de langage, lui correspond un argument, une proposition ; l'usage du point suivi d'un espace et d'une majuscule est assez général pour les identifier.\n-   des paragraphes : c'est une unité plus générale, qui souvent développe une idée.\n-   des sections, des chapitres, ou des livres : selon la nature des documents, cela permet de découper le corpus en sous-unités.\n\nLes *tokenizers* sont les outils indispensables à cette tâche. Dans cet ouvrage, nous nous concentrons sur l'étude des mots. Lors de cette étude, un certain nombre de mots apparaissent de nombreuses fois, pour permettre de donner du sens au langage humain, mais ils ne portent pas en eux d'informations particulièrement pertinentes pour l'analyse : ce sont les *stopwords*, qu'il conviendra souvent d'éliminer.\n\nLes n-grammes, quant à eux, représentent des suites de n *tokens*. Un unigramme est donc équivalent à un *token*, un digramme[^q07_tokenisation-1] est une suite de deux *tokens*, etc. L'identification des n-grammes permet de détecter des suites de *tokens* qui reviennent plus souvent que leur probabilité d'occurrences. Si l'on se concentre sur les mots, nous sommes alors face à une unité sémantique, comme on le comprend facilement avec le digramme 'Assemblée Nationale' dont le sens est plus que ses constituants.\n\n[^q07_tokenisation-1]: En français digramme est la meilleure traduction de bigram, une bigramme en français est un mot dont les lettres peuvent former deux autres mot.\n\nTokeniser revient donc à découper le texte pour en construire une représentation quantitative.C'est d'ailleurs une des spécificités des grands modèles de langage qui s'intréesse moins aux mots, qu'à ses décompositions, telles qu'un nombre limité( ~30 000) permette de générer la plupart des graphies et au passage de supporter les dysgraphies. \n\n## Quelques exercices de tokenization\n\n### Les lettres\n\nCommençons par un exemple simple, à l'aide d'une courte citation de Max Weber. On choisit les lettres pour unité de découpe, et l'on utilise le package ['tokenizer'](https://cran.r-project.org/web/packages/tokenizers/vignettes/introduction-to-tokenizers.html). Automatiquement, 'tokenizer' met le texte en minuscule et élimine la ponctuation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Les données\nMaxWeber <- paste0(\"Bureaucratie: le moyen le plus rationnel que l’on connaisse pour exercer un contrôle impératif sur des êtres humains.\")\n\n#On tokenise, plus on transforme en dataframe le résultat.\ntoc_maxweber<-tokenize_characters(MaxWeber)%>%\n        as.data.frame()%>%\n        rename(tokens=1)\n\n#On compte pour chaque token sa fréquence d'apparition\nfoo<-toc_maxweber %>% \n        group_by(tokens)%>% \n        summarise(n=n())%>%\n        filter(n>0)\n\n#On représente par un diagramme en barre cette distribution des occuences d'apparition, en classant les tokens par fréquence\nggplot(foo, aes(x=reorder(tokens,n), y=n))+\n               geom_bar(stat=\"identity\", fill=\"royalblue\")+\n        annotate(\"text\", x=10,y=10, label=paste(\"nombre de tokens =\", nrow(toc_maxweber)))+\n               coord_flip()+\n        labs(title = \"Fréquence des tokens, unité = lettres\", \n             x=\"tokens\", \n             y=\"nombre d'occurences\", \n             caption =\" 'Bureaucratie: le moyen le plus rationnel que l’on connaisse pour exercer un contrôle impératif sur des êtres humains.' \")\n```\n\n::: {.cell-output-display}\n![](q07_tokenisation_files/figure-html/601-1.png){width=672}\n:::\n:::\n\n\n### les mots\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Les données\n\nMaxWeber <- paste0(\"Bureaucratie: le moyen le plus rationnel que l’on connaisse pour exercer un contrôle impératif sur des êtres humains. La bureaucratie est une forme d'organisation générale caractérisée par la prépondérance des règles et de procédures qui sont appliquées de façon impersonnelle par des agents spécialisés. Ces agents appliquent les règles sans discuter des objectifs ou des raisons qui les fondent. Ils doivent faire preuve de neutralité et oublier leurs propres intérêts personnels au profit de l’intérêt général.\")\n\n#On tokenise, plus on transforme en dataframe le résultat. le strp_punc écarte la ponctuation du processus.\ntoc_maxweber<-tokenize_words(MaxWeber,strip_punct=TRUE)%>%\n        as.data.frame()%>%\n        rename(tokens=1)\n\n#On compte pour chaque token sa fréquence d'apparition\nfoo<-toc_maxweber %>%mutate(n=1) %>% \n        group_by(tokens)%>% \n        summarise(n=sum(n))\n\n#On représente par un diagramme en barre cette distribution des occurrences, en classant les tokens par fréquence\nggplot(foo, aes(x=reorder(tokens,n), y=n))+\n               geom_bar(stat=\"identity\", fill=\"royalblue\")+\n        annotate(\"text\", x=10,y=4, label=paste(\"nombre de tokens =\", nrow(toc_maxweber)))+\n               coord_flip()+labs(title = \"Fréquence des tokens, unité = mots\", x=\"tokens\", y=\"nombre d'occurences\", caption =\" 'Bureaucratie: le moyen le plus rationnel que l’on connaisse pour exercer un contrôle impératif sur des êtres humains.' \")\n```\n\n::: {.cell-output-display}\n![](q07_tokenisation_files/figure-html/602-1.png){width=672}\n:::\n:::\n\n\nOn peut également constater que certains mots sont proches, par exemple les deux derniers sur le graphiques précédents qui sont des déclinaisons du verbe appliquer. Il peut alors être pertinent de regrouper ces différentes formes verbales (comme un mot au singulier et au pluriel, au féminin et au masculin, ou conjugué sous différentes formes), pour faciliter l'analyse. C'est ce qu'on fait avec les opérations de *stemming* ou de lemmatisation, présentées au chapitre 8.\n\n### Les phrases\n\nOn reproduit les mêmes opérations, mais cette fois sur les phrases de l'exemple précédent.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntokenize_sentences(MaxWeber)%>%\n  as.data.frame()%>%\n  rename(tokens=1)%>%\n  flextable(cwidth = 6)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"tabwid\"><style>.cl-26f452d6{}.cl-26e45692{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-26e456a6{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-26ea7612{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-26eaa092{width:6in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-26eaa0a6{width:6in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-26eaa0a7{width:6in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-26eaa0b0{width:6in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-26f452d6'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-26eaa092\"><p class=\"cl-26ea7612\"><span class=\"cl-26e45692\">tokens</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-26eaa0a6\"><p class=\"cl-26ea7612\"><span class=\"cl-26e456a6\">Bureaucratie: le moyen le plus rationnel que l’on connaisse pour exercer un contrôle impératif sur des êtres humains.</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-26eaa0a7\"><p class=\"cl-26ea7612\"><span class=\"cl-26e456a6\">La bureaucratie est une forme d'organisation générale caractérisée par la prépondérance des règles et de procédures qui sont appliquées de façon impersonnelle par des agents spécialisés.</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-26eaa0a7\"><p class=\"cl-26ea7612\"><span class=\"cl-26e456a6\">Ces agents appliquent les règles sans discuter des objectifs ou des raisons qui les fondent.</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-26eaa0b0\"><p class=\"cl-26ea7612\"><span class=\"cl-26e456a6\">Ils doivent faire preuve de neutralité et oublier leurs propres intérêts personnels au profit de l’intérêt général.</span></p></td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n## N-grammes\n\nLes n-grammes sont des séquences de n *tokens*, généralement consécutifs. Sur la d'un base d'un corpus important on peut calculer la probabilité d'apparition d'un n-gramme. C'est l'exercice auquel une équipe de google s'est attelé avec le [Books Ngram Viewer](https://books.google.com/ngrams/). et dont nous encourageons l'étude détaillée.\n\nL'article original doit aussi être lu. Sur la base de 5 millions de livres numérisés en 2011 et représentant 4% du nombre total de livres à jamais publiés à ce moment, être lu aussi, il montre que, pour l'anglais, chaque année 8500 mots entrent dans le lexique, sans que les dictionnaires, pour des raisons évidentes de concision, n'en font l'inventaire. Le webster comprend 300 000 mots, alors que pour l'anglais l'estimation du nombre de termes différents, est passé de l'ordre de 500 000 en 1900, à plus d'1.5 million en 2000. Il donne aussi une dimension au lexique : celle de sa densité. Dans un corpus, à un moment donné quelle est la probabilité d'observer un token donné (au plus simple un mot). Sur un corpus de 500 milliards de termes (pour toutes les langues traitées), un mot qui apparaît une fois sur 1000 ( 10\\^-3), apparaît 5 millions de fois, s'il apparaît une fois sur 1 million, il apparaît 5000 fois. L'échelle de mesure est ainsi la fréquence : 10-3, 10-5, 10-6 ....\n\nLa notion de ngram au-delà de son apparence de tautologie possède aussi un intérêt théorique majeure. Les ngram sont des chaines de markov. Intérêt théorique des n gram : ce sont des chaines de markov.\n\n[Processus de markov](https://fr.wikipedia.org/wiki/N-gramme)\n\nPour comprendre l'importance de ce concept on peut considérer au moins 3 applications remarquables\n\nApplication à l'auto-complétion . Son efficacité dépend naturellement de la taille des données récoltées. On comprend que pour google il est aisé d'être précis dans l'estimation de ces probabilités!\n\nMais mieux encore, ces propriété markovienne ( probabilistique) permettent aussi la correction d'erreur avec l'algorithme de Viterbi https://fr.wikipedia.org/wiki/Algorithme_de_Viterbi\n\n-   Le principe de 'textcat' est fondée sur ces n-grammes de lettre. Chaque langue se caractérise par une distribution particulière des n-grammes. Pour décider de l'appartenance d'un texte à une langue, si on dispose des profils de distribution, on compare la distribution des n-grammes du texte à ces références. On peut ainsi calculer une distance et attribuer le texte à la langue dont il est le plus proche.\n\n### Mise en oeuvre\n\nSi la notion est simple, sa mise en oeuvre l'est presque autant. Nous l'illustrons avec une séries d'exemples et le package \"tokenizer\" qui a ici un avantage pédagogique. On étudiera plus loin les ressources de \"quanteda\".\n\nOn commence de suite par un exemple sur les lettres. c'est de pure forme. On sélectionne les ngrammes (k\\>1 et k\\>4) dont la fréquence est supérieure à trois.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#tokenization des lettres\ntoc_maxweber<-tokenize_character_shingles(MaxWeber,n=3, n_min=2) %>%\n        as.data.frame()%>%\n  rename(tokens=1)\n\nflextable(head(toc_maxweber, n=20))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"tabwid\"><style>.cl-271f22a4{}.cl-270a8182{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-270a8196{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2714adb0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-2714e230{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2714e244{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2714e24e{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2714e24f{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-271f22a4'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-2714e230\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8182\">tokens</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e244\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">bu</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">bur</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">ur</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">ure</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">re</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">rea</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">ea</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">eau</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">au</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">auc</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">uc</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">ucr</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">cr</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">cra</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">ra</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">rat</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">at</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">ati</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24e\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">ti</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2714e24f\"><p class=\"cl-2714adb0\"><span class=\"cl-270a8196\">tie</span></p></td></tr></tbody></table></div>\n```\n\n:::\n\n```{.r .cell-code}\nfoo<-toc_maxweber %>%mutate(n=1) %>% \n        group_by(tokens)%>% \n        summarise(n=sum(n))%>%\n  filter(n>3)\n\nggplot(foo, aes(x=reorder(tokens,n), y=n))+\n               geom_bar(stat=\"identity\", fill=\"royalblue\")+\n  annotate(\"text\", x=5,y=11, label=paste(\"nombre total de tokens =\", nrow(toc_maxweber)))+\n               coord_flip()+labs(title = \"digrammes et trigrammes des lettres\", x=\"n-gramme\", y=\"nombre d'occurences\")\n```\n\n::: {.cell-output-display}\n![](q07_tokenisation_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nOn peut faire la même chose sur les mots, et en plus en éliminant les *stopwords*. l'intérêt de la procédure est de se concentrer sur les idées, des paires de mots consistants du point de vue sémantique. Un ordre ce dégage ! la bureaucratie est un moyen, puis une rationalité qui dépend d'un exercice.\n\nOn note qu'il n'y a pas besoin de beaucoup de mots pour produire du sens par l'analyse statistique de leurs distributions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntoc_maxweber<-tokenize_ngrams(MaxWeber,\n                              n=3, \n                              n_min=2, \n                              stopwords = stopwords('fr')) %>%\n  as.data.frame()%>%\n  rename(tokens=1)\n\nqflextable(head(toc_maxweber, n=19))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"tabwid\"><style>.cl-27835e22{}.cl-27753bd0{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-27753be4{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-277a9eb8{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-277ac37a{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac384{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac38e{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac38f{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac398{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac399{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac3a2{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac3a3{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac3ac{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-277ac3ad{width:1.982in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-27835e22'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-277ac37a\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753bd0\">tokens</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac384\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">bureaucratie moyen</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac38e\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">bureaucratie moyen plus</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac38e\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">moyen plus</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac38e\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">moyen plus rationnel</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac38f\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">plus rationnel</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac398\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">plus rationnel l’on</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac399\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">rationnel l’on</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac399\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">rationnel l’on connaisse</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac399\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">l’on connaisse</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac399\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">l’on connaisse exercer</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3a2\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">connaisse exercer</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3a3\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">connaisse exercer contrôle</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3a3\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">exercer contrôle</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3ac\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">exercer contrôle impératif</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3ac\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">contrôle impératif</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3ac\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">contrôle impératif êtres</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3ac\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">impératif êtres</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3ac\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">impératif êtres humains</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-277ac3ad\"><p class=\"cl-277a9eb8\"><span class=\"cl-27753be4\">êtres humains</span></p></td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\nOn peut également s'intéresser aux n-grammes non directement consécutifs mais séparés par k *tokens*. C'est sans doute un moyen de saisir des corrélations de mots à plus grande distance. La possibilité formelle est là , nous avouons ne pas savoir à quel usage elle correspond. Nous serions sur ce point ravi d'avoir des réponses.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntoc_maxweber<-tokenize_skip_ngrams(MaxWeber,\n                                   n=3, \n                                   n_min=2, \n                                   k=2, \n                                   stopwords = stopwords('fr')) %>%\n        as.data.frame()%>%rename(tokens=1)\nqflextable(head(toc_maxweber, n=19))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"tabwid\"><style>.cl-27bd0104{}.cl-27a47efe{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-27a47f12{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-27aa1ae4{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-27aa3ac4{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27aa3ace{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27aa3ad8{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27aa3ad9{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27aa3ae2{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27aa3ae3{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27aa3aec{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27aa3aed{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27aa3af6{width:2.33in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-27bd0104'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-27aa3ac4\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47efe\">tokens</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ace\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie moyen</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ad8\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie plus</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ad9\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie rationnel</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae2\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie moyen plus</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae2\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie moyen rationnel</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae3\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie moyen l’on</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ad8\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie plus rationnel</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3aec\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie plus l’on</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ad8\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie plus connaisse</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3aed\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie rationnel l’on</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ad9\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie rationnel connaisse</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ad9\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">bureaucratie rationnel exercer</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae2\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">moyen plus</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae2\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">moyen rationnel</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae3\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">moyen l’on</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae2\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">moyen plus rationnel</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae3\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">moyen plus l’on</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3ae2\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">moyen plus connaisse</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27aa3af6\"><p class=\"cl-27aa1ae4\"><span class=\"cl-27a47f12\">moyen rationnel l’on</span></p></td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\nDans cet exemple, aucun n-gramme n'est répété, mais c'est rarement le cas avec des corpus plus importants. Dans ce cas, une forte répétition de n-grammes est un indice d'une unité sémantique composée de plusieurs *tokens* que l'on peut alors regrouper en un seul et même *token*. C'est ce que l'on verra dans la section suivante, avec la méthodes des collocation,\n\n## Choisir des n-grammes pertinents\n\nDans ce e-book l'unité principale d'analyse restera le mot. Mais nous savons, au moins intuitivement que certaines combinaisons de mots représentent des expressions qui ont la valeur d'un mot, une valeur sémantique, par exemple, l'expression \"Assemblée Nationale\". Ces deux mots réunis constituent un syntagme, une unité de sens. La question qui se pose est alors de savoir comment les identifier dans le flot des n-grammes ?\n\nLa technique est simple : si deux mots se retrouvent dans un ordre donné plus fréquemment que ce que le produit de leurs probabilités d'apparition laisse espérer, c'est qu'ils constituent une expression. On peut imaginer faire un test du chi² pour décider si un couple de mots constitue une unité sémantique ou non.\n\nLe package quanteda propose une bonne solution à ce problème avec la fonction collocation.\n\n### Créer les *tokens* avec 'quanteda'\n\nÀ partir du corpus des commentaires de TripAdvisor concernant les hôtels de Polynésie Française,\n\n\n::: {.cell tbl-cap='corpus'}\n\n```{.r .cell-code}\n#les données\nAvisTripadvisor<-read_rds(\"./data/AvisTripadvisor.rds\")\nAvisTripadvisor$Taille_hotel<-as.character(AvisTripadvisor$Taille_hotel)\nAvisTripadvisor$Taille_hotel[is.na(AvisTripadvisor$Taille_hotel)]<-\"Autre\"\n\n\n#création du corpus\ncorpus<-corpus(AvisTripadvisor,docid_field = \"ID\",text_field = \"Commetaire\", docvars =AvisTripadvisor)\nft<- head(corpus,3) %>% as.data.frame()%>%\n  rename(tokens=1)%>%\n  flextable(cwidth = 6)\nft\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"tabwid\"><style>.cl-2800fe04{}.cl-27f07066{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-27f07084{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-27f8151e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-27f8399a{width:6in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27f839a4{width:6in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27f839ae{width:6in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-27f839af{width:6in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-2800fe04'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-27f8399a\"><p class=\"cl-27f8151e\"><span class=\"cl-27f07066\">tokens</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27f839a4\"><p class=\"cl-27f8151e\"><span class=\"cl-27f07084\">Tout est magnifique au Vahine island. Séjour de rêve avec une équipe très chaleureuse . Le cadre est splendide. Notre meilleur hébergement en Polynésie.Merci à toute l' équipe pour votre gentillesse et vos nombreuses attentions.</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27f839ae\"><p class=\"cl-27f8151e\"><span class=\"cl-27f07084\">Tout était parfait, notre meilleure expérience et plus belle découverte en Polynésie.Un grand merci à Amélie et toute son équipe pour un service de très haut niveau.De la chambre, en passant par la restauration et les activités, tout était parfait. Encore merci à tous, en espérant revenir très vite.</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-27f839af\"><p class=\"cl-27f8151e\"><span class=\"cl-27f07084\">Un séjour magnifique, 3 jours époustouflants, accueillis chaleureusement par toute l’équipe du Vahine Island. Tout est au rendez vous, la cuisine délicieuse, le lieu au delà de notre imagination, un calme parfait. À faire, re faire, sans jamais s’en lasser.</span></p></td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\nOn crée un objet de format *token*, avec la fonction tokens de quanteda, et on choisit d'enlèver la ponctuation, les symboles et les nombres avec les arguments correspondants.\n\nNotre tokenizer ici a quelques problèmes . Si le \".\" n'est pas suivi d'un espace, il ne peut distinguer les mots, il ne saisit pas non plus l'ellipse de \"l'équipe\", qui devrait distinguer le determinant \"la\" de \"équipe. Souvent il faudra au préalable remanier les chaines de caractère pour une meilleure qualité de tokenisation.\n\n\n::: {.cell tbl-cap='token simple'}\n\n```{.r .cell-code}\n#transformation en objet token\ntok<-tokens(corpus,remove_punct = TRUE, remove_symbols=TRUE, remove_numbers=TRUE)\n\nhead(tok,3) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTokens consisting of 3 documents and 21 docvars.\n1 :\n [1] \"Tout\"       \"est\"        \"magnifique\" \"au\"         \"Vahine\"    \n [6] \"island\"     \"Séjour\"     \"de\"         \"rêve\"       \"avec\"      \n[11] \"une\"        \"équipe\"    \n[ ... and 22 more ]\n\n2 :\n [1] \"Tout\"         \"était\"        \"parfait\"      \"notre\"        \"meilleure\"   \n [6] \"expérience\"   \"et\"           \"plus\"         \"belle\"        \"découverte\"  \n[11] \"en\"           \"Polynésie.Un\"\n[ ... and 37 more ]\n\n3 :\n [1] \"Un\"              \"séjour\"          \"magnifique\"      \"jours\"          \n [5] \"époustouflants\"  \"accueillis\"      \"chaleureusement\" \"par\"            \n [9] \"toute\"           \"l’équipe\"        \"du\"              \"Vahine\"         \n[ ... and 27 more ]\n```\n\n\n:::\n:::\n\n\nAu passage, on peut aussi enlever les *stopwords*. C'est a dire les mots d'usages courants mais sans signification intrinsèque : les conjonctions, les déterminants, etc, qui se présentent sous la formes de dictionnaires.\n\nPour que les n-grammes très fréquents restent des syntagmes signifiants, on laisse apparentes les positions des *stopwords*, avec l'option `padding= TRUE`.\n\n\n::: {.cell tbl-cap='token with stopwords'}\n\n```{.r .cell-code}\n#enlever les stopwords\ntok<-tokens_remove(tok,stopwords('fr'),padding=FALSE)\nhead(tok, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTokens consisting of 3 documents and 21 docvars.\n1 :\n [1] \"Tout\"        \"magnifique\"  \"Vahine\"      \"island\"      \"Séjour\"     \n [6] \"rêve\"        \"équipe\"      \"très\"        \"chaleureuse\" \"cadre\"      \n[11] \"splendide\"   \"meilleur\"   \n[ ... and 7 more ]\n\n2 :\n [1] \"Tout\"         \"parfait\"      \"meilleure\"    \"expérience\"   \"plus\"        \n [6] \"belle\"        \"découverte\"   \"Polynésie.Un\" \"grand\"        \"merci\"       \n[11] \"Amélie\"       \"toute\"       \n[ ... and 18 more ]\n\n3 :\n [1] \"séjour\"          \"magnifique\"      \"jours\"           \"époustouflants\" \n [5] \"accueillis\"      \"chaleureusement\" \"toute\"           \"l’équipe\"       \n [9] \"Vahine\"          \"Island\"          \"Tout\"            \"rendez\"         \n[ ... and 13 more ]\n```\n\n\n:::\n:::\n\n\n### Application à la détection des entités nommées\n\nOn cherche ici à identifier les noms propres présents dans le corpus.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(quanteda.textstats)\n#on sélectionne les mots commençant par une majuscule\ntoks_cap <- tokens_select(tok, \n                               pattern = \"^[A-Z]\",\n                               valuetype = \"regex\",\n                               case_insensitive = FALSE, \n                               padding = TRUE)\n\n#on cherche les collocations\ntstat_col_cap <- textstat_collocations(toks_cap, min_count = 3, tolower = FALSE)\n\nflextable(head(as.data.frame(tstat_col_cap)))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"tabwid\"><style>.cl-294ab200{}.cl-29270620{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-29270634{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2939f5b4{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-2939f5c8{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-293a4f3c{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-293a4f50{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-293a4f5a{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-293a4f5b{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-293a4f64{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-293a4f6e{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-293a4f6f{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-293a4f78{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-294ab200'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-293a4f3c\"><p class=\"cl-2939f5b4\"><span class=\"cl-29270620\">collocation</span></p></th><th class=\"cl-293a4f50\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270620\">count</span></p></th><th class=\"cl-293a4f50\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270620\">count_nested</span></p></th><th class=\"cl-293a4f50\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270620\">length</span></p></th><th class=\"cl-293a4f50\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270620\">lambda</span></p></th><th class=\"cl-293a4f50\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270620\">z</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-293a4f5a\"><p class=\"cl-2939f5b4\"><span class=\"cl-29270634\">Bora Bora</span></p></td><td class=\"cl-293a4f5b\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">155</span></p></td><td class=\"cl-293a4f5b\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">0</span></p></td><td class=\"cl-293a4f5b\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">2</span></p></td><td class=\"cl-293a4f5b\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">6.604016</span></p></td><td class=\"cl-293a4f5b\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">53.27337</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-293a4f64\"><p class=\"cl-2939f5b4\"><span class=\"cl-29270634\">Sylvie Yves</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">21</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">0</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">2</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">8.183783</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">25.93161</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-293a4f64\"><p class=\"cl-2939f5b4\"><span class=\"cl-29270634\">Muriel Franck</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">19</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">0</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">2</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">7.141592</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">24.46065</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-293a4f64\"><p class=\"cl-2939f5b4\"><span class=\"cl-29270634\">Corinne Frédéric</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">17</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">0</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">2</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">8.609701</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">23.23737</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-293a4f64\"><p class=\"cl-2939f5b4\"><span class=\"cl-29270634\">Pearl Beach</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">13</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">0</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">2</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">8.037935</span></p></td><td class=\"cl-293a4f6e\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">21.75092</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-293a4f6f\"><p class=\"cl-2939f5b4\"><span class=\"cl-29270634\">Yves Sylvie</span></p></td><td class=\"cl-293a4f78\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">13</span></p></td><td class=\"cl-293a4f78\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">0</span></p></td><td class=\"cl-293a4f78\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">2</span></p></td><td class=\"cl-293a4f78\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">7.285754</span></p></td><td class=\"cl-293a4f78\"><p class=\"cl-2939f5c8\"><span class=\"cl-29270634\">21.32976</span></p></td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\n### Composer des *tokens* à partir d'expressions multi-mots : collocation\n\nDans ce corpus, les noms propres correspondent aux noms des îles et des hôtels, et aux prénoms composés. La valeur du lambda montre la force de l'association entre les mots, on retiendra d'une manière générale un lambda au moins supérieur à 3 pour remplacer les *tokens* d'origine par leurs n-grammes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntoks_comp <- tokens_compound(tok, pattern = tstat_col_cap[tstat_col_cap$z > 3,], \n                             case_insensitive = FALSE)\n\nhead(toks_comp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTokens consisting of 6 documents and 21 docvars.\n1 :\n [1] \"Tout\"        \"magnifique\"  \"Vahine\"      \"island\"      \"Séjour\"     \n [6] \"rêve\"        \"équipe\"      \"très\"        \"chaleureuse\" \"cadre\"      \n[11] \"splendide\"   \"meilleur\"   \n[ ... and 7 more ]\n\n2 :\n [1] \"Tout\"         \"parfait\"      \"meilleure\"    \"expérience\"   \"plus\"        \n [6] \"belle\"        \"découverte\"   \"Polynésie.Un\" \"grand\"        \"merci\"       \n[11] \"Amélie\"       \"toute\"       \n[ ... and 18 more ]\n\n3 :\n [1] \"séjour\"          \"magnifique\"      \"jours\"           \"époustouflants\" \n [5] \"accueillis\"      \"chaleureusement\" \"toute\"           \"l’équipe\"       \n [9] \"Vahine_Island\"   \"Tout\"            \"rendez\"          \"cuisine\"        \n[ ... and 12 more ]\n\n4 :\n [1] \"Vraiment\"    \"beau\"        \"cadre\"       \"idyllique\"   \"personnel\"  \n [6] \"très\"        \"attentionné\" \"adoré\"       \"séjour\"      \"attention\"  \n[11] \"spéciale\"    \"voyage\"     \n[ ... and 15 more ]\n\n5 :\n [1] \"Vahiné_Island\" \"entre\"         \"monde\"         \"parallèle\"    \n [5] \"où\"            \"sait\"          \"plus\"          \"très\"         \n [9] \"bien\"          \"tient\"         \"réel\"          \"tient\"        \n[ ... and 60 more ]\n\n6 :\n [1] \"adoré\"         \"séjour\"        \"Vahiné_Island\" \"enfants\"      \n [5] \"bungalow\"      \"pilotis\"       \"bungalow\"      \"plage\"        \n [9] \"c'était\"       \"paradis\"       \"motu\"          \"idyllique\"    \n[ ... and 40 more ]\n```\n\n\n:::\n:::\n\n\n### Identifier les autres concepts\n\nDans ce corpus, on peut aussi s'attendre à voir apparaître d'autres expressions multi-mots qui représentent des concepts, telles que \"petit déjeuner\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncol<-textstat_collocations(toks_comp, min_count = 10)\n\nflextable(head(as.data.frame(col)))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"tabwid\"><style>.cl-2cc3c62e{}.cl-2c9a4e34{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2c9a4e3e{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2caed8fe{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-2caed912{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-2cafe8ca{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cafe8de{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cafe8e8{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cafe8f2{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cafe8f3{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cafe8fc{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cafe906{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2cafe907{width:0.75in;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-2cc3c62e'><thead><tr style=\"overflow-wrap:break-word;\"><th class=\"cl-2cafe8ca\"><p class=\"cl-2caed8fe\"><span class=\"cl-2c9a4e34\">collocation</span></p></th><th class=\"cl-2cafe8de\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e34\">count</span></p></th><th class=\"cl-2cafe8de\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e34\">count_nested</span></p></th><th class=\"cl-2cafe8de\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e34\">length</span></p></th><th class=\"cl-2cafe8de\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e34\">lambda</span></p></th><th class=\"cl-2cafe8de\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e34\">z</span></p></th></tr></thead><tbody><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2cafe8e8\"><p class=\"cl-2caed8fe\"><span class=\"cl-2c9a4e3e\">petit déjeuner</span></p></td><td class=\"cl-2cafe8f2\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">769</span></p></td><td class=\"cl-2cafe8f2\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">0</span></p></td><td class=\"cl-2cafe8f2\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">2</span></p></td><td class=\"cl-2cafe8f2\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">6.955714</span></p></td><td class=\"cl-2cafe8f2\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">79.38781</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2cafe8f3\"><p class=\"cl-2caed8fe\"><span class=\"cl-2c9a4e3e\">très bien</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">714</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">0</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">2</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">3.022621</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">64.09272</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2cafe8f3\"><p class=\"cl-2caed8fe\"><span class=\"cl-2c9a4e3e\">très bon</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">422</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">0</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">2</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">3.506116</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">53.16466</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2cafe8f3\"><p class=\"cl-2caed8fe\"><span class=\"cl-2c9a4e3e\">salle bain</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">274</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">0</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">2</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">8.724142</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">52.20121</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2cafe8f3\"><p class=\"cl-2caed8fe\"><span class=\"cl-2c9a4e3e\">très agréable</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">374</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">0</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">2</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">3.636737</span></p></td><td class=\"cl-2cafe8fc\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">50.52490</span></p></td></tr><tr style=\"overflow-wrap:break-word;\"><td class=\"cl-2cafe906\"><p class=\"cl-2caed8fe\"><span class=\"cl-2c9a4e3e\">grand merci</span></p></td><td class=\"cl-2cafe907\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">167</span></p></td><td class=\"cl-2cafe907\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">0</span></p></td><td class=\"cl-2cafe907\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">2</span></p></td><td class=\"cl-2cafe907\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">5.112295</span></p></td><td class=\"cl-2cafe907\"><p class=\"cl-2caed912\"><span class=\"cl-2c9a4e3e\">50.38965</span></p></td></tr></tbody></table></div>\n```\n\n:::\n:::\n\n\nAu vue de la diversité des collocations, on choisit un lambda supérieur à 7 pour retenir les concepts les plus pertinents.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntoks_comp <- tokens_compound(tok, pattern = col[col$z > 7,])\n\nhead(toks_comp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTokens consisting of 6 documents and 21 docvars.\n1 :\n [1] \"Tout\"            \"magnifique\"      \"Vahine\"          \"island\"         \n [5] \"Séjour_rêve\"     \"équipe\"          \"très\"            \"chaleureuse\"    \n [9] \"cadre_splendide\" \"meilleur\"        \"hébergement\"     \"Polynésie.Merci\"\n[ ... and 4 more ]\n\n2 :\n [1] \"Tout_parfait\" \"meilleure\"    \"expérience\"   \"plus_belle\"   \"découverte\"  \n [6] \"Polynésie.Un\" \"grand_merci\"  \"Amélie\"       \"toute_équipe\" \"service\"     \n[11] \"très\"         \"haut\"        \n[ ... and 10 more ]\n\n3 :\n [1] \"séjour\"             \"magnifique\"         \"jours\"             \n [4] \"époustouflants\"     \"accueillis\"         \"chaleureusement\"   \n [7] \"toute_l’équipe\"     \"Vahine\"             \"Island\"            \n[10] \"Tout\"               \"rendez\"             \"cuisine_délicieuse\"\n[ ... and 11 more ]\n\n4 :\n [1] \"Vraiment\"                   \"beau\"                      \n [3] \"cadre_idyllique\"            \"personnel_très_attentionné\"\n [5] \"adoré_séjour\"               \"attention\"                 \n [7] \"spéciale\"                   \"voyage_noce\"               \n [9] \"soirée\"                     \"d’anniversaire\"            \n[11] \"paysage\"                    \"magnifique\"                \n[ ... and 9 more ]\n\n5 :\n [1] \"Vahiné\"    \"Island\"    \"entre\"     \"monde\"     \"parallèle\" \"où\"       \n [7] \"sait\"      \"plus\"      \"très_bien\" \"tient\"     \"réel\"      \"tient\"    \n[ ... and 45 more ]\n\n6 :\n [1] \"adoré_séjour\"     \"Vahiné\"           \"Island\"           \"enfants\"         \n [5] \"bungalow_pilotis\" \"bungalow_plage\"   \"c'était\"          \"paradis\"         \n [9] \"motu\"             \"idyllique\"        \"situé\"            \"lagon\"           \n[ ... and 33 more ]\n```\n\n\n:::\n:::\n\n\n## Des tokens au dtm\n\nD'un point de vue pratique le nombre de colonne est de l'ordre de plusieurs milliers. Dans le cas de texte courts, quelques dizaines, ou même centaine de mots, moins de quelques pour-cent des lignes auront une valeur. C'est un tableau creux (sparse matrix) qui peut nécessiter des représentations particulières et plus économes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#on transforme en document-features matrix pour des représentations graphiques \n\ndfm<-dfm(toks_comp,remove_padding=TRUE) \n\ndfm <- dfm_remove(dfm, stopwords(\"fr\"))\n\ndfm_top <- topfeatures(dfm, n = 80, decreasing = TRUE,  scheme =\"count\")\n\ndfm_top\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             a           très           plus           tout           bien \n          2345           1355           1194           1141            930 \n       pension        chambre          hôtel       bungalow             si \n           896            883            804            775            748 \n         c'est     restaurant            peu          plage           fait \n           740            716            702            670            663 \n           car          repas         séjour      personnel          faire \n           623            606            600            577            551 \n     bungalows        service          merci       vraiment     magnifique \n           527            480            479            475            472 \n         comme        piscine          lagon          aussi        cuisine \n           469            469            467            463            453 \n      chambres          c’est           donc        accueil petit_déjeuner \n           450            448            436            432            427 \n       l'hôtel          petit          super           tous            vue \n           426            419            395            392            386 \n       l’hôtel           soir           prix        surtout          juste \n           386            377            371            359            351 \n            où       toujours            bon            top        qualité \n           348            348            346            343            315 \n         quand        endroit       agréable           deux      polynésie \n           315            313            313            306            305 \n       famille          cadre      l'accueil       terrasse           nuit \n           303            302            299            294            288 \n    recommande          d'une           rien          calme           motu \n           284            284            281            279            276 \n     également        superbe             ça          n'est    gentillesse \n           275            267            266            265            257 \n          lieu       poissons       beaucoup          après      très_bien \n           257            254            254            253            248 \n          trop           être   restauration        journée          temps \n           247            247            246            246            244 \n```\n\n\n:::\n\n```{.r .cell-code}\n#un nuage de mots rapide library(quanteda.textplots) \n\ntextplot_wordcloud(dfm, max_word=80, color = rev(RColorBrewer::brewer.pal(6, \"RdBu\")))\n```\n\n::: {.cell-output-display}\n![Mots les plus fréquents du corpus](q07_tokenisation_files/figure-html/609-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndfm2<-dfm %>% dfm_subset(!is.na(Taille_hotel))%>%\n  dfm_group(groups = Taille_hotel)\n\n\ntextplot_wordcloud(dfm2, comparison = TRUE, max_words = 200,\n                   color = c(\"blue\", \"red\"))\n```\n\n::: {.cell-output-display}\n![Mots les plus fréquents du corpus](q07_tokenisation_files/figure-html/609-2.png){width=672}\n:::\n:::\n\n\n## La question des mots distinctifs\n\nPlus que comparer la fréquence des mots on peux souhaiter identifier ceux qui sont les plus discrimants, les plus distinctifs. \n\n### Keyness index\n\n\n### Find keywords based on the Textrank algorithm\n\nLe Textrank est un algorithme implémenté dans le paquetage R textrank. Cet algorithme permet de résumer un texte et d'en extraire des mots-clés. Pour ce faire, il construit un réseau de mots en vérifiant si les mots se suivent. Sur ce réseau, l'algorithme \"Google Pagerank\" est appliqué pour extraire les mots pertinents, après quoi les mots pertinents qui se suivent sont combinés pour obtenir des mots-clés. Dans l'exemple ci-dessous, nous souhaitons trouver des mots-clés à l'aide de cet algorithme pour les noms ou les adjectifs qui se suivent. Le graphique ci-dessous montre que les mots-clés combinent les mots pour former des expressions à plusieurs mots.\n\n### Rake \n\nL'algorithme de base suivant s'appelle RAKE, acronyme de Rapid Automatic Keyword Extraction (extraction automatique rapide de mots clés). Il recherche des mots-clés en examinant une séquence contiguë de mots qui ne contient pas de mots non pertinents. En d'autres termes, il\n\nen calculant un score pour chaque mot faisant partie d'un mot-clé candidat.\nparmi les mots des mots-clés candidats, l'algorithme examine le nombre d'occurrences de chaque mot et le nombre de cooccurrences avec d'autres mots. Chaque mot obtient un score qui est le rapport entre le degré du mot (le nombre de fois qu'il cooccurre avec d'autres mots) et la fréquence du mot. un score RAKE pour le mot-clé candidat complet est calculé en additionnant les scores de chacun des mots qui définissent le mot-clé candidat.\n\n\n## Conclusion\n\nDans ce chapitre, nous avons vu comment découper un corpus en unités, les *tokens*. Nous avons abordé le sujet des n-grammes, et vu comment composer des *tokens* à partir de concepts multi-mots, identifiés par des n-grammes adjacents.\n\nOn conclue sur l'idée que la distribution des termes d'un texte doit se comprendre dans deux dimensions : la fréquence des termes parmi tous les termes, leur fréquence à travers les documents.\n",
    "supporting": [
      "q07_tokenisation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/tabwid-1.1.3/tabwid.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/tabwid-1.1.3/tabwid.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}