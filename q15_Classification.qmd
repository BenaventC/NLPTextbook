# Classification with embeddings

**Objectifs du chapitre :**

<div>

*L'histoire de la linguistique computationnelle est intimement liée au machine learning, et à la tâche de classification. Le principe général de l'apprentissage artificiel consiste d'abord à choisir les caractéristiques qui vont être employées pour prédire une variable donnée, ensuite à choisir un modèle, puis à entraîner sur un premier jeu de donnée, et enfin à l'évaluer sur la base d'un second échantillon de données. Le processus est itératifs et vise à choisir les hyper-paramètres les plus adéquation pour maximiser la capacité prédictive du modèle*

</div>

**Environnement de travail**

```{r 600}
#les librairies du chapître
library(tidyverse)
library(tokenizers)
library(quanteda)
library(quanteda.textplots)
library(flextable)

theme_set(theme_minimal()) 

set_flextable_defaults(
  font.size = 10, theme_fun = theme_vanilla,
  padding = 6,
  background.color = "#EFEFEF")
```

## Un cadre général

![Processus d'apprentissage machine](image/ML2024.png)

-jouer avec les [réseaux de neurone](https://playground.tensorflow.org/) est forment recommandé.

### Ce qu'on cherche à prédire

le rôle central de l'annotation.

L'enjeu de l'annotation humaine. kappa.

### Avec quoi on cherche à prédire

le featuring

les embeddings comme featuring, et un saut dans la performance

### Les modèles

| Col1         | Continu            | binaire           | polytomique       |
|--------------|--------------------|-------------------|-------------------|
| generation 1 | regression         | Naive Bayes       |                   |
|              | Arbre de décision  |                   |                   |
| génération 2 | lasso ( penalized) | Random forets     | Random forest     |
| génération 3 | réseaux neuronaux  | réseaux neuronaux | réseaux neuronaux |

### Entrainement

### Validation

précision /rappel

roc

### Déploiement et inférence

## Un exemple simple : Naive bayes vs random forest

Naive bayes :

Random forest :

### le processus

### les résultats

## Un exemple plus avancé : du Bert sentiment

les modèles de langage fournissent un bon featuring

### le processus

### les résultats

## Conclusion

Application à de nombreux concepts : - toxicité, "profanité", complotisme - POS, - sentiment, émotions, personnalité ... - detection d'élément thématiques - temporalité

Lourdeur de l'approche, incertitude du résultat : vers une approche plus directe : le zeroshot classiqcation et le NER.
